<!doctype html>
<html lang="en">
    <head>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=IBM+Plex+Serif:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">

        <link
            rel="stylesheet"
            href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css"
            integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g=="
            crossorigin="anonymous"
            referrerpolicy="no-referrer"/>

        <!-- math rendering -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

        <meta charset="UTF-8" />
        <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üó∫Ô∏è</text></svg>">
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link href="/index.css" rel="stylesheet">

        <title>Scale-ALiBi</title>
    </head>
    <body>
        <div class="post-layout">
            <nav>

            </nav>
            <article>
                <h1 class="has-authors">Multi-modal, Multi-scale Representation Learning for Satellite Imagery Analysis Just Needs a Good ALiBi</h1>
                <div class="authors">
                    <a target="_blank" href="//ka.ge">Patrick Kage</a><sup>1</sup> and <a href="https://www.linkedin.com/in/pandreadis/">Pavlos Andreadis</a><sup>1</sup>
                </div>

                <div class="institution">
                    <sup>1</sup><a target="_blank" href="https://web.inf.ed.ac.uk/aiai">Artificial Intelligence and its Applications Institute</a>, The University of Edinburgh
                </div>

                <div class="paperlinks">
                    <a href="https://kage.zip/papers/kage_siw_workshop_2024.pdf" target="_blank" class="paperlink"><i class="fa-solid fa-book"></i> <span>Paper</span></a>
                    <a href="//github.com/pkage/scale-alibi" target="_blank" class="paperlink"><i class="fa-brands fa-github"></i> <span>Source code</span></a>
                    <a href="https://kage.zip/papers/kage_siw_slides_2024.pdf" target="_blank" class="paperlink"><i class="fa-solid fa-person-chalkboard"></i> <span>Slides</span></a>
                    <a href="#dataset" data-scrollto="dataset" class="paperlink"><i class="fa-solid fa-database"></i> <span>Dataset</span></a>
                </div>
                
                

                <h2>Abstract</h2>

                <p>
                    Vision foundation models have been shown to be effective at processing
                    satellite imagery into representations fit for downstream tasks, however,
                    creating models which operate over multiple spatial resolutions and modes
                    is challenging. This paper presents Scale-ALiBi, a linear bias transformer
                    attention mechanism with a spatial encoding bias to relationships between
                    image patches at different ground sample distance scales. We provide an
                    implementation of Scale-ALiBi over a dataset of aligned high- and
                    low-resolution optical and low-resolution SAR satellite imagery data using
                    a triple-contrastive and reconstructive architecture, show an improvement
                    on the GEO-Bench benchmark, and release the newly curated dataset publicly.
                </p>

                <h2>Architecture</h2>

                <img src="architecture.svg" class="figure" alt="scale-alibi architecture">

                <p>
                    <i>Figure. </i> The Scale-ALiBi architecture. Read the full paper <a href="https://kage.zip/papers/kage_siw_workshop_2024.pdf" target="_blank">here</a>.
                </p>
                

                <h2 id="dataset">Datasets</h2>

                <p>
                    Alongside the Scale-ALiBi model, we release the dataset
                    used in training. The dataset is generated by processing
                    Sentinel-1 and Sentinel-2 images, segmenting them into <a href="https://en.wikipedia.org/wiki/Tiled_web_map" target="_blank">XYZ</a>
                    tiles of 256x256 pixel resolution. Sentinel-2‚Äôs true-color
                    images are directly segmented, while Sentinel-1 images
                    undergo scaling and band manipulation to create 8-bit
                    optical-like representations. High-resolution images from
                    NAIP are used to match the same tiles, and the next Y-level
                    down is included as well. Due to the constraints of NAIP,
                    the dataset is geographically limited to the continental
                    U.S. and Puerto Rico, with smaller regions selected for
                    coverage based on diversity and scale. Various dataset
                    sizes are made available, see below for download links.
                </p>
                
                <div class="map-controls">
                    <select name="dataset" id="mapdataset">
                        <option value="" selected disabled hidden>Dataset</option>
                        <option value="full">Full</option>
                        <option value="small">Small</option>
                        <option value="micro">Micro</option>
                    </select>
                    <select name="bands" id="mapbands">
                        <option value="" selected disabled hidden>Samples</option>
                        <option value="radar">Synthetic-aperture Radar (Sentinel-1)</option>
                        <option value="lores">Low-resolution Optical (Sentinel-2)</option>
                        <option value="hires">High-resolution Optical (NAIP)</option>
                    </select>
                    <select name="grid" id="mapgrid">
                        <option value="" selected disabled hidden>Grid</option>
                        <option value="on">Grid on</option>
                        <option value="off">Grid off</option>
                    </select>

                    <button type="button" id="mapshow">Show</button>
                </div>
                
            </article>
            <div class="map-container">
                <div id="map"></div>
                
            </div>
            <article>
                <h2>Dataset downloads</h2>

                <p>
                These datasets are provided as <a href="https://docs.protomaps.com/pmtiles/">Protomap tile bundles</a>.
                Please see the <a href="https://github.com/pkage/scale-alibi">source</a> for examples on how to load
                    and process these datasets.
                </p>
                

                <ul>
                    <li>
                        <strong>Full</strong> <i class="sample-count">146,502 joint samples</i>
                        <ul>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/sar_tiles.pmtile" target="_blank">sar_tiles.pmtile</a> <span>(304,882 tiles, 6.3 GB)</span>
                            </li>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/visual_tiles.pmtile" target="_blank">visual_tiles.pmtile</a> <span>(186,250 tiles, 5.6 GB)</span>
                            </li>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/hires_visual_tiles.pmtile" target="_blank">hires_visual_tiles.pmtile</a> <span>(983,795 tiles, 10.2 GB)</span>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <strong>Small</strong> <i class="sample-count">21,497 joint samples</i>
                        <ul>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/sar_tiles_small.pmtile" target="_blank">sar_tiles_small.pmtile</a> <span>(83,407 tiles, 2.0 GB)</span>
                            </li>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/visual_tiles_small.pmtile" target="_blank">visual_tiles_small.pmtile</a> <span>(21,917 tiles, 771.1 MB)</span>
                            </li>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/hires_visual_tiles_small.pmtile" target="_blank">hires_visual_tiles_small.pmtile</a> <span>(109,585 tiles, 1.5 GB)</span>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <strong>Micro</strong> <i class="sample-count">188,060 joint samples</i>
                        <ul>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/sar_tiles_micro.pmtile" target="_blank">sar_tiles_micro.pmtile</a> <span>(939,398 tiles, 2.0 GB)</span>
                            </li>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/visual_tiles_micro.pmtile" target="_blank">visual_tiles_micro.pmtile</a> <span>(188,060 tiles, 1.0 GB)</span>
                            </li>
                            <li>
                                <a href="https://se7a6ueojehnth4fhglodzchw40rfbuv.lambda-url.us-east-2.on.aws/hires_visual_tiles_micro.pmtile" target="_blank">hires_visual_tiles_micro.pmtile</a> <span>(940,300 tiles, 10.4 GB)</span>
                            </li>
                        </ul>
                    </li>
                </ul>

            </article>
            <footer>
                <span>Patrick Kage &bull; 08 Oct 2024</span>
            </footer>
            <!--div id="map"></div-->
        </div>
        
        <script type="module" src="/main.js"></script>
        <script type="module" src="/scroller.js"></script>
    </body>
</html>
